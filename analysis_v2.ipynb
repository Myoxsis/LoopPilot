{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis v2: scikit-learn-based supplier cleansing\n",
    "\n",
    "This notebook aligns the exploratory workflow with the TF-IDF matcher in `utils_supplier_name`. It demonstrates how the scikit-learn logic cleans supplier names, handles prioritized columns, and feeds normalized data into simple routing/geolocation steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from utils_data_cleansing import apply_rule, load_rules\n",
    "from utils_geoloc import get_geoloc, load_data\n",
    "from utils_supplier_name import (\n",
    "    batch_guess_supplier_names,\n",
    "    build_tfidf_matcher,\n",
    "    guess_supplier_name_from_priority,\n",
    "    load_supplier_names,\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleansing assets\n",
    "\n",
    "The matching helpers depend on the rule set in `rules.yml`, the supplier baseline in `CONSIGNEE_NAME.csv`, and the geolocation mapping in `geoloc.yml`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "rules = load_rules('rules.yml')\n",
    "known_suppliers = load_supplier_names('CONSIGNEE_NAME.csv')\n",
    "geoloc_rules, geoloc_warnings = load_data('geoloc.yml')\n",
    "\n",
    "print(f\"Loaded {len(rules)} rules and {len(known_suppliers)} canonical supplier names.\")\n",
    "print(f\"Geolocation rules: {len(geoloc_rules)} entries; warnings: {geoloc_warnings}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample shipments\n",
    "\n",
    "A compact dataset mixes clean and noisy consignee spellings along with a secondary booking name column. The cities are kept simple so the focus stays on the name cleansing behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_shipments = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            'tms_id': 1,\n",
    "            'consignee_name': 'Huebner GmbH',\n",
    "            'booking_name': 'Hubner',\n",
    "            'loading_city': 'Amsterdam',\n",
    "            'consignee_city': 'Hannover',\n",
    "        },\n",
    "        {\n",
    "            'tms_id': 2,\n",
    "            'consignee_name': 'DB cargo',\n",
    "            'booking_name': 'Deutsche Bahn AG',\n",
    "            'loading_city': 'Paris',\n",
    "            'consignee_city': 'Berlin',\n",
    "        },\n",
    "        {\n",
    "            'tms_id': 3,\n",
    "            'consignee_name': 'Kable Technik Polska',\n",
    "            'booking_name': 'Kabel Technik Polska',\n",
    "            'loading_city': 'Aachen',\n",
    "            'consignee_city': 'Wroclaw',\n",
    "        },\n",
    "        {\n",
    "            'tms_id': 4,\n",
    "            'consignee_name': 'Knorr-Brems',\n",
    "            'booking_name': '',\n",
    "            'loading_city': 'Vienna',\n",
    "            'consignee_city': 'Munich',\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "raw_shipments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize consignee names with TF-IDF\n",
    "\n",
    "The scikit-learn flow fits a character-level TF-IDF model once via `build_tfidf_matcher`, then reuses it inside `batch_guess_supplier_names` and `guess_supplier_name_from_priority`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit a reusable matcher on the canonical supplier list.\n",
    "vectorizer, tfidf_matrix, canonical_suppliers = build_tfidf_matcher(known_suppliers)\n",
    "\n",
    "raw_shipments['normalized_consignee'] = batch_guess_supplier_names(\n",
    "    raw_shipments['consignee_name'],\n",
    "    canonical_suppliers,\n",
    "    rules=rules,\n",
    "    min_score=0.7,\n",
    ")\n",
    "\n",
    "raw_shipments['priority_normalized'] = raw_shipments.apply(\n",
    "    lambda row: guess_supplier_name_from_priority(\n",
    "        [row['consignee_name'], row['booking_name']],\n",
    "        canonical_suppliers,\n",
    "        rules=rules,\n",
    "        min_score=0.7,\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "raw_shipments[['tms_id', 'consignee_name', 'booking_name', 'normalized_consignee', 'priority_normalized']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geolocate shipment endpoints\n",
    "\n",
    "Once names are normalized, the helper coordinates can be attached to each shipment. Unknown cities default to `[0.0, 0.0]` so downstream routing logic can flag them.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_shipments['pickup_coords'] = raw_shipments['loading_city'].apply(\n",
    "    lambda name: get_geoloc(name, geoloc_rules, default_return=[0.0, 0.0])\n",
    ")\n",
    "raw_shipments['delivery_coords'] = raw_shipments['consignee_city'].apply(\n",
    "    lambda name: get_geoloc(name, geoloc_rules, default_return=[0.0, 0.0])\n",
    ")\n",
    "\n",
    "raw_shipments[['pickup_lat', 'pickup_lon']] = pd.DataFrame(\n",
    "    raw_shipments['pickup_coords'].tolist(), index=raw_shipments.index\n",
    ")\n",
    "raw_shipments[['delivery_lat', 'delivery_lon']] = pd.DataFrame(\n",
    "    raw_shipments['delivery_coords'].tolist(), index=raw_shipments.index\n",
    ")\n",
    "\n",
    "raw_shipments[\n",
    "    ['tms_id', 'normalized_consignee', 'pickup_lat', 'pickup_lon', 'delivery_lat', 'delivery_lon']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "The normalized names and coordinates can now feed the routing prototype (e.g., nearest-neighbor loops or clustering). Because the TF-IDF matcher is pre-fit, the same vectorizer can be reused for larger datasets without changing the cleansing behavior.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}