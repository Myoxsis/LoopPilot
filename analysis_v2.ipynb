{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated analysis with helper functions\n",
    "\n",
    "This notebook reworks the original exploratory analysis to use the reusable helpers for supplier name normalization and geolocation lookups. It demonstrates a lightweight pipeline on a small sample of shipments so the logic can be exercised without large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from utils_data_cleansing import load_rules\n",
    "from utils_geoloc import get_geoloc, load_data\n",
    "from utils_supplier_name import (\n",
    "    guess_supplier_name,\n",
    "    guess_supplier_name_from_priority,\n",
    "    load_supplier_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load rule and reference data\n",
    "\n",
    "The cleansing and geolocation helpers operate on YAML and CSV reference files stored in the repository. If PyYAML is not installed, `utils_geoloc.load_data` will fall back to a minimal parser while `utils_data_cleansing.load_rules` requires PyYAML. Warnings are captured for missing files so they can be surfaced downstream.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = load_rules(\"rules.yml\")\n",
    "known_suppliers = load_supplier_names(\"CONSIGNEE_NAME.csv\")\n",
    "geoloc_rules, geoloc_warnings = load_data(\"geoloc.yml\")\n",
    "\n",
    "print(f\"Loaded {len(rules)} cleansing rules and {len(known_suppliers)} supplier names.\")\n",
    "print(f\"Geolocation rules: {len(geoloc_rules)} entries; warnings: {geoloc_warnings}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a small shipment sample\n",
    "\n",
    "The sample mixes clean and noisy supplier names along with imperfect location spellings. The priority-based helper shows how multiple raw columns can be evaluated without duplicating logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_shipments = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"tms_id\": 1,\n",
    "            \"consignee_name\": \"Huebner GmbH\",\n",
    "            \"fallback_name\": \"Hubner\",\n",
    "            \"loading_city\": \"Amsterdam\",\n",
    "            \"consignee_city\": \"Hannover\",\n",
    "        },\n",
    "        {\n",
    "            \"tms_id\": 2,\n",
    "            \"consignee_name\": \"DB\",\n",
    "            \"fallback_name\": \"Deutsche Bahn AG\",\n",
    "            \"loading_city\": \"Paris\",\n",
    "            \"consignee_city\": \"Berlin\",\n",
    "        },\n",
    "        {\n",
    "            \"tms_id\": 3,\n",
    "            \"consignee_name\": \"   ALSTOM  transport  \",\n",
    "            \"fallback_name\": \"Alstom\",\n",
    "            \"loading_city\": \"Lisboa\",\n",
    "            \"consignee_city\": \"Madrid\",\n",
    "        },\n",
    "        {\n",
    "            \"tms_id\": 4,\n",
    "            \"consignee_name\": None,\n",
    "            \"fallback_name\": \"Knorr-Bremse\",\n",
    "            \"loading_city\": \"Munich\",\n",
    "            \"consignee_city\": \"Vienna\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "raw_shipments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize supplier names\n",
    "\n",
    "`guess_supplier_name_from_priority` is used to evaluate the preferred and fallback supplier name columns. The function leverages `utils_data_cleansing.apply_rule` under the hood when rules are provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_shipments[\"normalized_consignee\"] = raw_shipments.apply(\n",
    "    lambda row: guess_supplier_name_from_priority(\n",
    "        [row[\"consignee_name\"], row[\"fallback_name\"]],\n",
    "        known_suppliers,\n",
    "        rules=rules,\n",
    "        min_score=0.65,\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "raw_shipments[[\"tms_id\", \"consignee_name\", \"fallback_name\", \"normalized_consignee\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geolocate shipment endpoints\n",
    "\n",
    "The geolocation helper returns coordinates for normalized place names. A default of `[0.0, 0.0]` is used when a city is missing from `geoloc.yml`, and warnings from the loader can be logged or inspected separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_shipments[\"pickup_coords\"] = raw_shipments[\"loading_city\"].apply(\n",
    "    lambda name: get_geoloc(name, geoloc_rules, default_return=[0.0, 0.0])\n",
    ")\n",
    "raw_shipments[\"delivery_coords\"] = raw_shipments[\"consignee_city\"].apply(\n",
    "    lambda name: get_geoloc(name, geoloc_rules, default_return=[0.0, 0.0])\n",
    ")\n",
    "\n",
    "# Split the coordinate pairs into separate columns for easier analysis\n",
    "raw_shipments[[\"pickup_lat\", \"pickup_lon\"]] = pd.DataFrame(\n",
    "    raw_shipments[\"pickup_coords\"].tolist(), index=raw_shipments.index\n",
    ")\n",
    "raw_shipments[[\"delivery_lat\", \"delivery_lon\"]] = pd.DataFrame(\n",
    "    raw_shipments[\"delivery_coords\"].tolist(), index=raw_shipments.index\n",
    ")\n",
    "\n",
    "raw_shipments[\n",
    "    [\n",
    "        \"tms_id\",\n",
    "        \"loading_city\",\n",
    "        \"pickup_lat\",\n",
    "        \"pickup_lon\",\n",
    "        \"consignee_city\",\n",
    "        \"delivery_lat\",\n",
    "        \"delivery_lon\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Use the normalized consignee names and coordinates as the basis for the milkrun loop designs. The same pattern can be scaled to full datasets by adding distance calculations, clustering, and vehicle constraints. The outputs below keep the notebook focused on showing how the cleaned data feeds routing heuristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype milkrun loop sketch\n",
    "\n",
    "The table now contains normalized consignee names alongside pickup and delivery coordinates. A simple nearest-neighbor heuristic can draft loop candidates so planners can review the ordering before applying more robust optimization. The example below separates pickup and delivery legs and reports the cumulative kilometers driven for each loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    radius_km = 6371\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(dlambda / 2) ** 2\n",
    "    return 2 * radius_km * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "def build_loop(points):\n",
    "    if points.empty:\n",
    "        return [], 0.0\n",
    "\n",
    "    remaining = list(range(len(points)))\n",
    "    route = [remaining.pop(0)]  # start from the first stop\n",
    "\n",
    "    while remaining:\n",
    "        current = route[-1]\n",
    "        next_idx = min(remaining, key=lambda idx: haversine(\n",
    "            points.iloc[current][\"lat\"], points.iloc[current][\"lon\"], points.iloc[idx][\"lat\"], points.iloc[idx][\"lon\"]\n",
    "        ))\n",
    "        route.append(next_idx)\n",
    "        remaining.remove(next_idx)\n",
    "\n",
    "    km_total = 0.0\n",
    "    for prev, nxt in zip(route, route[1:]):\n",
    "        km_total += haversine(\n",
    "            points.iloc[prev][\"lat\"], points.iloc[prev][\"lon\"], points.iloc[nxt][\"lat\"], points.iloc[nxt][\"lon\"]\n",
    "        )\n",
    "    return route, km_total\n",
    "\n",
    "pickup_points = raw_shipments[[\"loading_city\", \"pickup_lat\", \"pickup_lon\"]].rename(columns={\"pickup_lat\": \"lat\", \"pickup_lon\": \"lon\"})\n",
    "delivery_points = raw_shipments[[\"consignee_city\", \"delivery_lat\", \"delivery_lon\"]].rename(columns={\"delivery_lat\": \"lat\", \"delivery_lon\": \"lon\"})\n",
    "\n",
    "pickup_route, pickup_km = build_loop(pickup_points)\n",
    "delivery_route, delivery_km = build_loop(delivery_points)\n",
    "\n",
    "pickup_plan = pickup_points.iloc[pickup_route].reset_index(drop=True)\n",
    "pickup_plan[\"km_from_prev\"] = [0.0] + [\n",
    "    haversine(\n",
    "        pickup_plan.iloc[i - 1][\"lat\"],\n",
    "        pickup_plan.iloc[i - 1][\"lon\"],\n",
    "        pickup_plan.iloc[i][\"lat\"],\n",
    "        pickup_plan.iloc[i][\"lon\"]\n",
    "    )\n",
    "    for i in range(1, len(pickup_plan))\n",
    "]\n",
    "\n",
    "delivery_plan = delivery_points.iloc[delivery_route].reset_index(drop=True)\n",
    "delivery_plan[\"km_from_prev\"] = [0.0] + [\n",
    "    haversine(\n",
    "        delivery_plan.iloc[i - 1][\"lat\"],\n",
    "        delivery_plan.iloc[i - 1][\"lon\"],\n",
    "        delivery_plan.iloc[i][\"lat\"],\n",
    "        delivery_plan.iloc[i][\"lon\"]\n",
    "    )\n",
    "    for i in range(1, len(delivery_plan))\n",
    "]\n",
    "\n",
    "print(\"Pickup loop (nearest-neighbor)\")\n",
    "print(pickup_plan.assign(km_total=pickup_km))\n",
    "print(\"\\nDelivery loop (nearest-neighbor)\")\n",
    "print(delivery_plan.assign(km_total=delivery_km))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}